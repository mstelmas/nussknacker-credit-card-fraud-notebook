{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39acea4a-ca5a-40d3-ae55-d3e1a5adaee2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is based on this [notebook](https://gist.github.com/jedrz/ab2b00dacec8c049a7a54a9ebc004867) that is a part of the [\"ML models inference in fraud detection\"](https://nussknacker.io/blog/ml-models-inference-in-fraud-detection/) blogpost and uses the [Kaggle dataset](https://www.kaggle.com/datasets/neharoychoudhury/credit-card-fraud-data) containing credit card fraud data. The exploratory data analysis (EDA) and feature engineering for this dataset is omitted here - refer to the mentioned blogpost for details regarding those topics.\n",
    "\n",
    "The goal of this notebook is to present a short step by step guide from training a simple ML model to deploying it to the **Databricks Managed MLFlow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3c715a-151e-4da7-b321-462c4c1f91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.compose\n",
    "import mlflow\n",
    "import mlflow.models\n",
    "import mlflow.types.schema\n",
    "import imblearn.over_sampling\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89b9da-61b1-4f7a-b633-fe7341a0b991",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "\n",
    "In this section, we cleanup and prepare the [Kaggle dataset](https://www.kaggle.com/datasets/neharoychoudhury/credit-card-fraud-data) for model training. As already mentioned, we do not go into details regarding this process and we mostly reuse the code from this [notebook](https://gist.github.com/jedrz/ab2b00dacec8c049a7a54a9ebc004867)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63daa733-bfc8-4aaa-b715-544f2db1e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fraud_data.csv\")\n",
    "data = data.drop('trans_num', axis='columns', errors='ignore')\n",
    "data = data[(data['is_fraud'] == '0') | (data['is_fraud'] == '1')]\n",
    "data = data.map(lambda x: x.strip('\"') if isinstance(x, str) else x)\n",
    "data['trans_date_trans_time'] = data['trans_date_trans_time'].apply(lambda x: pd.to_datetime(x, dayfirst=True))\n",
    "data['dob'] = data['dob'].apply(lambda x: pd.to_datetime(x, dayfirst=True))\n",
    "data = data.astype({\n",
    "    'merchant': 'category',\n",
    "    'category': 'category',\n",
    "    'city': 'category',\n",
    "    'state': 'category',\n",
    "    'job': 'category',\n",
    "    'is_fraud': 'int',\n",
    "})\n",
    "data = data.astype({'is_fraud': 'boolean',})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7526e-7187-4fd7-b2dc-ca3c4dd06462",
   "metadata": {},
   "source": [
    "Next, we split the prepared dataset into training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a897b9f-1d6f-4010-837b-0278fb0684f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = sklearn.model_selection.train_test_split(data, random_state=random_state)\n",
    "train_data_input = train_data.drop('is_fraud', axis='columns')\n",
    "test_data_input = test_data.drop('is_fraud', axis='columns')\n",
    "train_data_output = train_data['is_fraud']\n",
    "test_data_output = test_data['is_fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877747bb-a29c-443f-b5fb-4bc005686b32",
   "metadata": {},
   "source": [
    "Note that the training dataset is heavily unbalanced towards negative classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7448d57a-b8b3-4a90-a1fe-3b00c4ce372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "False    9456\n",
       "True     1377\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_output.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993e5d5-0e5c-47a2-b031-65879788d36e",
   "metadata": {},
   "source": [
    "Therefore to improve the training process, we will over sample the training dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81bb7db-73a4-4151-b996-478da6183b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "False    9456\n",
       "True     9456\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_sampler = imblearn.over_sampling.RandomOverSampler(random_state=random_state)\n",
    "train_data_input, train_data_output = over_sampler.fit_resample(train_data_input, train_data_output)\n",
    "train_data_output.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9d2f8-6d19-46a5-b78f-e56b27914aed",
   "metadata": {},
   "source": [
    "The last thing to notice is that the testing dataset is unbalanced as well. This, however is not a problem - we just need to keep this in mind during model evaluation process by using metrics functions adjusted to unbalanced datasets (eg: `balanced_accuracy_score`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b18fec3-2c5e-460b-9c6d-5d87c7a57d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "False    3144\n",
       "True      467\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_output.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac515ff8-7713-4344-bb16-95ee84561784",
   "metadata": {},
   "source": [
    "# Model training and deployment to the **Databricks Managed MLFlow**\n",
    "\n",
    "With the training and testing datasets prepared, we begin training the ML model. Since the model is only for demonstration purposes, we pick a simple tree classifier selected by performing 5-fold cross-validation on a set of hyperparameters. The selected best model is evaluated on the testing dataset and then the achieved performance metrics, the model's hyperparameters and the model itself are all logged into the **Databricks Managed MLFlow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ea838a-68fa-4cb3-81e2-4db1983ac365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
     "Best model parameters: {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__max_depth': None, 'decisiontreeclassifier__min_impurity_decrease': 0.0, 'decisiontreeclassifier__min_samples_leaf': 2, 'decisiontreeclassifier__min_samples_split': 2}\n",
     "Best training accuracy: 0.9548432947474529\n",
     "For parameters: {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__max_depth': None, 'decisiontreeclassifier__min_impurity_decrease': 0.0, 'decisiontreeclassifier__min_samples_leaf': 2, 'decisiontreeclassifier__min_samples_split': 2}, accuracy: 0.6140478311565893, precision: 0.8369260917731867 and recall: 0.8565494322902243 was achieved\n",
     "Successfully registered model 'credit-card-fraud-classifier'.\n",
     "2025/03/20 13:47:52 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: credit-card-fraud-classifier, version 1\n",
     "Created version '1' of model 'credit-card-fraud-classifier'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"credit-card-fraud-classifier\"\n",
    "\n",
    "model = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.compose.make_column_transformer(\n",
    "        (sklearn.preprocessing.OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\"), ['merchant', 'category', 'city', 'state', 'job']),\n",
    "    ),\n",
    "    sklearn.tree.DecisionTreeClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "parameter_grid = {\n",
    "    'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "    'decisiontreeclassifier__min_impurity_decrease': [0.0, 0.05, 0.3],\n",
    "    'decisiontreeclassifier__max_depth': [None, 3, 5, 10],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 5, 10, 20],\n",
    "    'decisiontreeclassifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks\")\n",
    "with mlflow.start_run():\n",
    "    grid_search = sklearn.model_selection.GridSearchCV(\n",
    "        model, \n",
    "        parameter_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # select the best model from a given set of hyperparameters\n",
    "    grid_search.fit(train_data_input, train_data_output)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best model parameters:\", best_params)\n",
    "    print(\"Best training accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_data_predicted = best_model.predict(test_data_input)\n",
    "\n",
    "    # Note: we use balanced_accurace_score and average='weighted' to deal with imbalanced testing dataset.\n",
    "    accuracy = sklearn.metrics.balanced_accuracy_score(test_data_output, test_data_predicted)\n",
    "    precision = sklearn.metrics.precision_score(test_data_output, test_data_predicted, average='weighted')\n",
    "    recall = sklearn.metrics.recall_score(test_data_output, test_data_predicted, average='weighted')\n",
    "\n",
    "    print(f\"For parameters: {best_params}, accuracy: {accuracy}, precision: {precision} and recall: {recall} was achieved\")\n",
    "    \n",
    "    # Log all the classifier hyperparameters.\n",
    "    mlflow.log_param(\"criterion\", best_params['decisiontreeclassifier__criterion'])\n",
    "    mlflow.log_param(\"min_impurity_decrease\", best_params['decisiontreeclassifier__min_impurity_decrease'])\n",
    "    mlflow.log_param(\"max_depth\", best_params['decisiontreeclassifier__max_depth'])\n",
    "    mlflow.log_param(\"min_samples_split\", best_params['decisiontreeclassifier__min_samples_split'])\n",
    "    mlflow.log_param(\"min_samples_leaf\", best_params['decisiontreeclassifier__min_samples_leaf'])\n",
    "    \n",
    "    # Log metrics of the trained classifer.\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    \n",
    "    # Log the trained classifier itself.\n",
    "    model_signature = mlflow.models.infer_signature(model_input=train_data_input.iloc[:1], model_output=test_data_predicted[:1])\n",
    "    model_signature.outputs = mlflow.types.schema.Schema([mlflow.types.schema.ColSpec(\"double\")])\n",
    "    mlflow.sklearn.log_model(best_model, artifact_path=model_name, signature=model_signature, registered_model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
